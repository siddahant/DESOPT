{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+gXqwd+y3X3M9ts6gGdyJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mgHyIpAZsNpt"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd.functional import jacobian"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define objective fucntion\n",
        "f =lambda x: x[0] ** 2 + x[1] ** 2 + x[2] ** 2 \n",
        "\n",
        "# define constraints\n",
        "h1 = lambda x: ((x[0] ** 2) / 4) + ((x[1] ** 2) / 5) + ((x[2] ** 2) / 25) - 1\n",
        "h2 = lambda x: x[0] + x[1] - x[2]\n",
        "\n",
        "# initialize Variables\n",
        "x = Variable(torch.tensor([0.1,1.,1.]), requires_grad=True)\n",
        "eps= 1e-03"
      ],
      "metadata": {
        "id": "BKuMBc-7tLIS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have $n=3$ and $m=2$ here, so the DOF of systme is $n-m = 1$ \\\n",
        "meanwe have only one decision variable variable and two state variable \\\n",
        "let say: \\\n",
        "$x_1 $ here is the decision variable \\\n",
        "$ x_2$  and  $x_3$ are the state variables \\\n"
      ],
      "metadata": {
        "id": "Q8V6wrHQoEVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Reduce Gradient using jacobian\n",
        "def RJ(f,h1,h2,x):\n",
        "  #compute Jacobian\n",
        "  Jocobian = torch.zeros((3, 3))\n",
        "  Jocobian[0] = jacobian(f, (x))\n",
        "  Jocobian[1] = jacobian(h1, (x))\n",
        "  Jocobian[2] = jacobian(h2, (x))\n",
        "\n",
        "  # reduce Gradient variables\n",
        "  dfdd = Jocobian[0,0]\n",
        "  dfds = Jocobian[0,1:]\n",
        "  dhds = Jocobian[1:,1:]\n",
        "  dhdd = Jocobian[1:,0]\n",
        "\n",
        "  #compute reduce Gradient \n",
        "  DfDd =  dfdd - torch.matmul(torch.matmul(dfds,torch.pinverse(dhds)),dhdd)\n",
        "  return  DfDd, dfdd, dfds, dhds, dhdd"
      ],
      "metadata": {
        "id": "hKz5vRGshq2F"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qmjSuGPsB8X"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LM(x):\n",
        "  ''' Levenberg -Marquardt'''\n",
        "  Lambda = 1. \n",
        "  norm = torch.norm(torch.tensor([h1(x),h2(x)]))\n",
        "  while norm >1e-06 :\n",
        "      ReduceJacobian, dfdd, dfds, dhds, dhdd= RJ(f,h1,h2,x)\n",
        "      with torch.no_grad():\n",
        "          # Newton Method\n",
        "          x[1:] = x[1:] - torch.matmul(torch.matmul(torch.pinverse(torch.matmul(dhds.T,dhds) + Lambda* torch.eye(2)), dhds.T),torch.tensor([h1(x),h2(x)]))\n",
        "      norm= torch.norm(torch.tensor([h1(x),h2(x)]))\n",
        "  return x\n",
        "  \n",
        "def newX(x, alpha):\n",
        "    updatedx = torch.zeros(3)\n",
        "    ReduceJacobian, dfdd, dfds, dhds, dhdd= RJ(f,h1,h2,x)\n",
        "    updatedx[0] = x[0] - alpha * ReduceJacobian\n",
        "    updatedx[1:] = x[1:] + (alpha * (torch.matmul(torch.pinverse(dhds),dhdd))*ReduceJacobian)\n",
        "    return updatedx\n",
        "\n",
        "\n",
        "def lineSearch(x, t0=0.5, K=25):\n",
        "    ReduceJacobian, dfdd, dfds, dhds, dhdd= RJ(f,h1,h2,x)\n",
        "    alpha = 1\n",
        "    i = 0\n",
        "    func = f(newX(x, alpha))\n",
        "    phi = f(x) - (t0 * alpha * (ReduceJacobian ** 2))\n",
        "    while func > phi and i < K:\n",
        "        alpha = 0.5 * alpha\n",
        "        func = f(newX(x, alpha))\n",
        "        phi = f(x)- (t0 * alpha * (ReduceJacobian ** 2))\n",
        "        i += 1\n",
        "    return alpha"
      ],
      "metadata": {
        "id": "Q0YI3Bmjz_rG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRG(x,eps= 1e-03):\n",
        "    ReduceJacobian, dfdd, dfds, dhds, dhdd= RJ(f,h1,h2,x)\n",
        "    e = torch.norm(ReduceJacobian)\n",
        "    x_val = [x.detach().numpy()]\n",
        "    x= LM(x)\n",
        "    x_val.append(x.detach().numpy())\n",
        "    DfDd_val = [f(x).item()]\n",
        "    alpha_val = [1]\n",
        "    error_Val = [e]\n",
        "    k = 0\n",
        "    while e > eps:\n",
        "\n",
        "        alpha = lineSearch(x) # step 4.1\n",
        "        ReduceJacobian, dfdd, dfds, dhds, dhdd= RJ(f,h1,h2,x)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x[0] = x[0] - alpha * ReduceJacobian # setp 4.2\n",
        "            x[1:] = x[1:] + (alpha * np.matmul(torch.pinverse(dhds) ,  dhdd) *  ReduceJacobian) # step 4.3\n",
        "\n",
        "        x = LM(x)  # step 4.4\n",
        "        e = torch.norm(ReduceJacobian)  #step 4.5\n",
        "\n",
        "        # record values\n",
        "        x_val.append(x.detach().numpy())\n",
        "        DfDd_val.append(f(x).item())\n",
        "        alpha_val.append(alpha)\n",
        "        error_Val.append(e)\n",
        "        k +=1        \n",
        "    return x_val, DfDd_val, alpha_val, error_Val"
      ],
      "metadata": {
        "id": "Tzg_UtPR2WHi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRG(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfuAQ03T6fe7",
        "outputId": "ce91f8f9-a475-48de-964c-3a3606c54e8c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32),\n",
              "  array([-1.5737593 ,  1.3770875 , -0.19667158], dtype=float32)],\n",
              " [8.598715782165527,\n",
              "  6.722302436828613,\n",
              "  5.586321830749512,\n",
              "  4.742733001708984,\n",
              "  4.5450873374938965,\n",
              "  4.451842308044434,\n",
              "  4.420396327972412,\n",
              "  4.416024684906006,\n",
              "  4.413811206817627,\n",
              "  4.4127278327941895,\n",
              "  4.412212371826172,\n",
              "  4.4119720458984375,\n",
              "  4.411861419677734,\n",
              "  4.411810874938965,\n",
              "  4.411787509918213,\n",
              "  4.411777019500732,\n",
              "  4.411772727966309,\n",
              "  4.411770343780518,\n",
              "  4.411768436431885,\n",
              "  4.411767959594727,\n",
              "  4.411767959594727],\n",
              " [1,\n",
              "  0.25,\n",
              "  0.125,\n",
              "  0.125,\n",
              "  0.0625,\n",
              "  0.0625,\n",
              "  0.0625,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.03125,\n",
              "  0.0625,\n",
              "  0.125,\n",
              "  0.125],\n",
              " [tensor(1.1167),\n",
              "  tensor(2.5823),\n",
              "  tensor(3.0616),\n",
              "  tensor(2.7880),\n",
              "  tensor(1.9143),\n",
              "  tensor(1.3571),\n",
              "  tensor(0.8161),\n",
              "  tensor(0.4037),\n",
              "  tensor(0.2884),\n",
              "  tensor(0.2023),\n",
              "  tensor(0.1399),\n",
              "  tensor(0.0958),\n",
              "  tensor(0.0651),\n",
              "  tensor(0.0440),\n",
              "  tensor(0.0296),\n",
              "  tensor(0.0199),\n",
              "  tensor(0.0133),\n",
              "  tensor(0.0089),\n",
              "  tensor(0.0060),\n",
              "  tensor(0.0020),\n",
              "  tensor(0.0007)])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6HQREZeTfwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}